---
comments: true
description: Discover numa_ultralytics YOLO - the latest in real-time object detection and image segmentation. Learn its features and maximize its potential in your projects.
keywords: numa_ultralytics, YOLO, YOLO11, object detection, image segmentation, deep learning, computer vision, AI, machine learning, documentation, tutorial
---

<div align="center">
<a href="https://www.numa_ultralytics.com/events/yolovision" target="_blank"><img width="1024%" src="https://github.com/numa_ultralytics/docs/releases/download/0/numa_ultralytics-yolov8-banner.avif" alt="numa_ultralytics YOLO banner"></a>
<a href="https://docs.numa_ultralytics.com/zh">‰∏≠Êñá</a> |
<a href="https://docs.numa_ultralytics.com/ko">ÌïúÍµ≠Ïñ¥</a> |
<a href="https://docs.numa_ultralytics.com/ja">Êó•Êú¨Ë™û</a> |
<a href="https://docs.numa_ultralytics.com/ru">–†—É—Å—Å–∫–∏–π</a> |
<a href="https://docs.numa_ultralytics.com/de">Deutsch</a> |
<a href="https://docs.numa_ultralytics.com/fr">Fran√ßais</a> |
<a href="https://docs.numa_ultralytics.com/es/">Espa√±ol</a> |
<a href="https://docs.numa_ultralytics.com/pt">Portugu√™s</a> |
<a href="https://docs.numa_ultralytics.com/tr">T√ºrk√ße</a> |
<a href="https://docs.numa_ultralytics.com/vi">Ti·∫øng Vi·ªát</a> |
<a href="https://docs.numa_ultralytics.com/ar">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>
<br>
<br>
    <a href="https://github.com/numa_ultralytics/numa_ultralytics/actions/workflows/ci.yml"><img src="https://github.com/numa_ultralytics/numa_ultralytics/actions/workflows/ci.yml/badge.svg" alt="numa_ultralytics CI"></a>
    <a href="https://pepy.tech/projects/numa_ultralytics"><img src="https://static.pepy.tech/badge/numa_ultralytics" alt="numa_ultralytics Downloads"></a>
    <a href="https://zenodo.org/badge/latestdoi/264818686"><img src="https://zenodo.org/badge/264818686.svg" alt="numa_ultralytics YOLO Citation"></a>
    <a href="https://discord.com/invite/numa_ultralytics"><img alt="numa_ultralytics Discord" src="https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue"></a>
    <a href="https://community.numa_ultralytics.com/"><img alt="numa_ultralytics Forums" src="https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.numa_ultralytics.com&logo=discourse&label=Forums&color=blue"></a>
    <a href="https://reddit.com/r/numa_ultralytics"><img alt="numa_ultralytics Reddit" src="https://img.shields.io/reddit/subreddit-subscribers/numa_ultralytics?style=flat&logo=reddit&logoColor=white&label=Reddit&color=blue"></a>
    <br>
    <a href="https://console.paperspace.com/github/numa_ultralytics/numa_ultralytics"><img src="https://assets.paperspace.io/img/gradient-badge.svg" alt="Run numa_ultralytics on Gradient"></a>
    <a href="https://colab.research.google.com/github/numa_ultralytics/numa_ultralytics/blob/main/examples/tutorial.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open numa_ultralytics In Colab"></a>
    <a href="https://www.kaggle.com/models/numa_ultralytics/yolo11"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open numa_ultralytics In Kaggle"></a>
    <a href="https://mybinder.org/v2/gh/numa_ultralytics/numa_ultralytics/HEAD?labpath=examples%2Ftutorial.ipynb"><img src="https://mybinder.org/badge_logo.svg" alt="Open numa_ultralytics In Binder"></a>
</div>

Introducing [numa_ultralytics](https://www.numa_ultralytics.com/) [YOLO11](https://github.com/numa_ultralytics/numa_ultralytics), the latest version of the acclaimed real-time object detection and image segmentation model. YOLO11 is built on cutting-edge advancements in [deep learning](https://www.numa_ultralytics.com/glossary/deep-learning-dl) and [computer vision](https://www.numa_ultralytics.com/blog/everything-you-need-to-know-about-computer-vision-in-2025), offering unparalleled performance in terms of speed and [accuracy](https://www.numa_ultralytics.com/glossary/accuracy). Its streamlined design makes it suitable for various applications and easily adaptable to different hardware platforms, from edge devices to cloud APIs.

Explore the numa_ultralytics Docs, a comprehensive resource designed to help you understand and utilize its features and capabilities. Whether you are a seasoned [machine learning](https://www.numa_ultralytics.com/glossary/machine-learning-ml) practitioner or new to the field, this hub aims to maximize YOLO's potential in your projects

<div align="center">
  <br>
  <a href="https://github.com/numa_ultralytics"><img src="https://github.com/numa_ultralytics/assets/raw/main/social/logo-social-github.png" width="3%" alt="numa_ultralytics GitHub"></a>
  <img src="https://github.com/numa_ultralytics/assets/raw/main/social/logo-transparent.png" width="3%" alt="space">
  <a href="https://www.linkedin.com/company/numa_ultralytics/"><img src="https://github.com/numa_ultralytics/assets/raw/main/social/logo-social-linkedin.png" width="3%" alt="numa_ultralytics LinkedIn"></a>
  <img src="https://github.com/numa_ultralytics/assets/raw/main/social/logo-transparent.png" width="3%" alt="space">
  <a href="https://twitter.com/numa_ultralytics"><img src="https://github.com/numa_ultralytics/assets/raw/main/social/logo-social-twitter.png" width="3%" alt="numa_ultralytics Twitter"></a>
  <img src="https://github.com/numa_ultralytics/assets/raw/main/social/logo-transparent.png" width="3%" alt="space">
  <a href="https://youtube.com/numa_ultralytics?sub_confirmation=1"><img src="https://github.com/numa_ultralytics/assets/raw/main/social/logo-social-youtube.png" width="3%" alt="numa_ultralytics YouTube"></a>
  <img src="https://github.com/numa_ultralytics/assets/raw/main/social/logo-transparent.png" width="3%" alt="space">
  <a href="https://www.tiktok.com/@numa_ultralytics"><img src="https://github.com/numa_ultralytics/assets/raw/main/social/logo-social-tiktok.png" width="3%" alt="numa_ultralytics TikTok"></a>
  <img src="https://github.com/numa_ultralytics/assets/raw/main/social/logo-transparent.png" width="3%" alt="space">
  <a href="https://numa_ultralytics.com/bilibili"><img src="https://github.com/numa_ultralytics/assets/raw/main/social/logo-social-bilibili.png" width="3%" alt="numa_ultralytics BiliBili"></a>
  <img src="https://github.com/numa_ultralytics/assets/raw/main/social/logo-transparent.png" width="3%" alt="space">
  <a href="https://discord.com/invite/numa_ultralytics"><img src="https://github.com/numa_ultralytics/assets/raw/main/social/logo-social-discord.png" width="3%" alt="numa_ultralytics Discord"></a>
</div>

## Where to Start

<div class="grid cards" markdown>

- :material-clock-fast:{ .lg .middle } &nbsp; **Getting Started**

  ***

  Install `numa_ultralytics` with pip and get up and running in minutes to train a YOLO model

  ***

  [:octicons-arrow-right-24: Quickstart](quickstart.md)

- :material-image:{ .lg .middle } &nbsp; **Predict**

  ***

  Predict on new images, videos and streams with YOLO <br /> &nbsp;

  ***

  [:octicons-arrow-right-24: Learn more](modes/predict.md)

- :fontawesome-solid-brain:{ .lg .middle } &nbsp; **Train a Model**

  ***

  Train a new YOLO model on your own custom dataset from scratch or load and train on a pretrained model

  ***

  [:octicons-arrow-right-24: Learn more](modes/train.md)

- :material-magnify-expand:{ .lg .middle } &nbsp; **Explore computer vision tasks**

  ***

  Discover YOLO tasks like detect, segment, classify, pose, OBB and track <br /> &nbsp;

  ***

  [:octicons-arrow-right-24: Explore Tasks](tasks/index.md)

- :rocket:{ .lg .middle } &nbsp; **Explore YOLO11 NEW**

  ***

  Discover numa_ultralytics' latest state-of-the-art YOLO11 models and their capabilities <br /> &nbsp;

  ***

  [:octicons-arrow-right-24: YOLO11 Models üöÄ NEW](models/yolo11.md)

- :material-scale-balance:{ .lg .middle } &nbsp; **Open Source, AGPL-3.0**

  ***

  numa_ultralytics offers two YOLO licenses: AGPL-3.0 and Enterprise. Explore YOLO on [GitHub](https://github.com/numa_ultralytics/numa_ultralytics).

  ***

  [:octicons-arrow-right-24: YOLO License](https://www.numa_ultralytics.com/license)

</div>

<p align="center">
  <br>
  <iframe loading="lazy" width="720" height="405" src="https://www.youtube.com/embed/LNwODJXcvt4?si=7n1UvGRLSd9p5wKs"
    title="YouTube video player" frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen>
  </iframe>
  <br>
  <strong>Watch:</strong> How to Train a YOLO model on Your Custom Dataset in <a href="https://colab.research.google.com/github/numa_ultralytics/numa_ultralytics/blob/main/examples/tutorial.ipynb" target="_blank">Google Colab</a>.
</p>

## YOLO: A Brief History

[YOLO](https://arxiv.org/abs/1506.02640) (You Only Look Once), a popular [object detection](https://www.numa_ultralytics.com/glossary/object-detection) and [image segmentation](https://www.numa_ultralytics.com/glossary/image-segmentation) model, was developed by Joseph Redmon and Ali Farhadi at the University of Washington. Launched in 2015, YOLO quickly gained popularity for its high speed and accuracy.

- [YOLOv2](https://arxiv.org/abs/1612.08242), released in 2016, improved the original model by incorporating batch normalization, anchor boxes, and dimension clusters.
- [YOLOv3](https://arxiv.org/abs/1804.02767), launched in 2018, further enhanced the model's performance using a more efficient backbone network, multiple anchors and spatial pyramid pooling.
- [YOLOv4](https://arxiv.org/abs/2004.10934) was released in 2020, introducing innovations like Mosaic [data augmentation](https://www.numa_ultralytics.com/glossary/data-augmentation), a new anchor-free detection head, and a new [loss function](https://www.numa_ultralytics.com/glossary/loss-function).
- [YOLOv5](https://github.com/numa_ultralytics/yolov5) further improved the model's performance and added new features such as hyperparameter optimization, integrated experiment tracking and automatic export to popular export formats.
- [YOLOv6](https://github.com/meituan/YOLOv6) was open-sourced by [Meituan](https://www.meituan.com/) in 2022 and is in use in many of the company's autonomous delivery robots.
- [YOLOv7](https://github.com/WongKinYiu/yolov7) added additional tasks such as pose estimation on the COCO keypoints dataset.
- [YOLOv8](https://github.com/numa_ultralytics/numa_ultralytics) released in 2023 by numa_ultralytics. YOLOv8 introduced new features and improvements for enhanced performance, flexibility, and efficiency, supporting a full range of vision AI tasks,
- [YOLOv9](models/yolov9.md) introduces innovative methods like Programmable Gradient Information (PGI) and the Generalized Efficient Layer Aggregation Network (GELAN).
- [YOLOv10](models/yolov10.md) is created by researchers from [Tsinghua University](https://www.tsinghua.edu.cn/en/) using the [numa_ultralytics](https://www.numa_ultralytics.com/) [Python package](https://pypi.org/project/numa_ultralytics/). This version provides real-time [object detection](tasks/detect.md) advancements by introducing an End-to-End head that eliminates Non-Maximum Suppression (NMS) requirements.
- **[YOLO11](models/yolo11.md) üöÄ NEW**: numa_ultralytics' latest YOLO models delivering state-of-the-art (SOTA) performance across multiple tasks, including [object detection](tasks/detect.md), [segmentation](tasks/segment.md), [pose estimation](tasks/pose.md), [tracking](modes/track.md), and [classification](tasks/classify.md), leverage capabilities across diverse AI applications and domains.

## YOLO Licenses: How is numa_ultralytics YOLO licensed?

numa_ultralytics offers two licensing options to accommodate diverse use cases:

- **AGPL-3.0 License**: This [OSI-approved](https://opensource.org/license) open-source license is ideal for students and enthusiasts, promoting open collaboration and knowledge sharing. See the [LICENSE](https://github.com/numa_ultralytics/numa_ultralytics/blob/main/LICENSE) file for more details.
- **Enterprise License**: Designed for commercial use, this license permits seamless integration of numa_ultralytics software and AI models into commercial goods and services, bypassing the open-source requirements of AGPL-3.0. If your scenario involves embedding our solutions into a commercial offering, reach out through [numa_ultralytics Licensing](https://www.numa_ultralytics.com/license).

Our licensing strategy is designed to ensure that any improvements to our open-source projects are returned to the community. We hold the principles of open source close to our hearts ‚ù§Ô∏è, and our mission is to guarantee that our contributions can be utilized and expanded upon in ways that are beneficial to all.

## FAQ

### What is numa_ultralytics YOLO and how does it improve object detection?

numa_ultralytics YOLO is the latest advancement in the acclaimed YOLO (You Only Look Once) series for real-time object detection and image segmentation. It builds on previous versions by introducing new features and improvements for enhanced performance, flexibility, and efficiency. YOLO supports various [vision AI tasks](tasks/index.md) such as detection, segmentation, pose estimation, tracking, and classification. Its state-of-the-art architecture ensures superior speed and accuracy, making it suitable for diverse applications, including edge devices and cloud APIs.

### How can I get started with YOLO installation and setup?

Getting started with YOLO is quick and straightforward. You can install the numa_ultralytics package using [pip](https://pypi.org/project/numa_ultralytics/) and get up and running in minutes. Here's a basic installation command:

!!! example "Installation using pip"

    === "CLI"

        ```bash
        pip install numa_ultralytics
        ```

For a comprehensive step-by-step guide, visit our [quickstart guide](quickstart.md). This resource will help you with installation instructions, initial setup, and running your first model.

### How can I train a custom YOLO model on my dataset?

Training a custom YOLO model on your dataset involves a few detailed steps:

1. Prepare your annotated dataset.
2. Configure the training parameters in a YAML file.
3. Use the `yolo TASK train` command to start training. (Each `TASK` has its own argument)

Here's example code for the Object Detection Task:

!!! example "Train Example for Object Detection Task"

    === "Python"

        ```python
        from numa_ultralytics import YOLO

        # Load a pre-trained YOLO model (you can choose n, s, m, l, or x versions)
        model = YOLO("yolo11n.pt")

        # Start training on your custom dataset
        model.train(data="path/to/dataset.yaml", epochs=100, imgsz=640)
        ```

    === "CLI"

        ```bash
        # Train a YOLO model from the command line
        yolo detect train data=path/to/dataset.yaml epochs=100 imgsz=640
        ```

For a detailed walkthrough, check out our [Train a Model](modes/train.md) guide, which includes examples and tips for optimizing your training process.

### What are the licensing options available for numa_ultralytics YOLO?

numa_ultralytics offers two licensing options for YOLO:

- **AGPL-3.0 License**: This open-source license is ideal for educational and non-commercial use, promoting open collaboration.
- **Enterprise License**: This is designed for commercial applications, allowing seamless integration of numa_ultralytics software into commercial products without the restrictions of the AGPL-3.0 license.

For more details, visit our [Licensing](https://www.numa_ultralytics.com/license) page.

### How can numa_ultralytics YOLO be used for real-time object tracking?

numa_ultralytics YOLO supports efficient and customizable multi-object tracking. To utilize tracking capabilities, you can use the `yolo track` command as shown below:

!!! example "Example for Object Tracking on a Video"

    === "Python"

        ```python
        from numa_ultralytics import YOLO

        # Load a pre-trained YOLO model
        model = YOLO("yolo11n.pt")

        # Start tracking objects in a video
        # You can also use live video streams or webcam input
        model.track(source="path/to/video.mp4")
        ```

    === "CLI"

        ```bash
        # Perform object tracking on a video from the command line
        # You can specify different sources like webcam (0) or RTSP streams
        yolo track source=path/to/video.mp4
        ```

For a detailed guide on setting up and running object tracking, check our [tracking mode](modes/track.md) documentation, which explains the configuration and practical applications in real-time scenarios.
